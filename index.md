David Tsukamoto
dtsukamoto@ucsd.edu
B01, Kyle Nero

What is the most interesting topic covered in your domain this quarter?
** The most interesting topic that we covered this quarter was the different techniques used in natural language processing to carry out things like classification or prediction. Our mentor gave us freedom to explore our own options, so while we initially worked with tf-idf since we've used it before, we moved to embeddings created by DistilBERT which is an NLP model. Exploring the different methods of NLP and how they work with classification models is interesting to me and was fun to work on. **

Describe a potential investigation you would like to pursue for your Quarter 2 Project.
** One direction our project could go in for Quarter 2 could be a classification project that also involves NLP such as fraud detection. Since this quarter, we've already been working with text data and have been seeking to classify them, this would simply change our project from one focused on multi-class classifcation, to a binary classification. While the texts might be different, they would carry similar procedures such as data exploration, cleaning and model creation. **

What is a potential change youâ€™d make to the approach taken in your current Quarter 1 Project?
** One change I would make in my approach to the Quarter 1 is spending more time on the cleaning portion of our work. We are working with bank transaction memos to predict its category. While we did spend a lot of time doing it, I feel that with more time, we could get a slightly better dataset to feed into our classification models. Since it is the basis of what our model uses to predict, I think that it's one of the most essential parts of our project this quarter, so improving on that could always be done. **

What other techniques would you be interested in using in your project?
** Another technique that I would be interested in using would be the use of a LLM, which while very inefficient, would be intestesting to compare against our current techniques. LLMs take much more time and aren't needed for a task like this, but it would be interesting to use. Another technique to try would be bag of words, which is a much simpler version of converting words to numbers, so it could work well with some models. Other techniques would be using different classifiers like XGBoost to test our data on. **
